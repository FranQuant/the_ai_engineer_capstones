{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce788974-bae7-48f4-9817-1ee550ef8459",
   "metadata": {},
   "source": [
    "# 02 â€” PyTorch Implementation (No Autograd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ee607-da99-415c-b6ca-5b4d4f37f73a",
   "metadata": {},
   "source": [
    "## 1. Imports & Deterministic Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a134e7-b3d7-4fff-8332-2a0d14bdfd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392240b-ccf5-43c5-8555-8a2dd50f1316",
   "metadata": {},
   "source": [
    "## 2. Synthetic Dataset (same as Notebook 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21dc0422-762c-4391-942b-9fe757c6ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X shape: (N, 2), y shape: (N,)\n",
    "# Use the same seed so samples match NumPy network\n",
    "N = 200\n",
    "X_np = np.random.uniform(-1, 1, size=(N, 2))\n",
    "y_np = (X_np[:, 0] * X_np[:, 1] < 0).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd3356-5b89-4f7d-87cd-8a647a734904",
   "metadata": {},
   "source": [
    "#### Convert to PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92dfad0-3425-440e-9353-646c83a3ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d3a172-21d1-4096-877e-14eca1a27144",
   "metadata": {},
   "source": [
    "## 3. NumPy Reference Forward Pass (from Notebook 01)\n",
    "To ensure numerical parity between the NumPy and PyTorch implementations,\n",
    "we replicate the minimal forward-pass functions from Notebook 01. These\n",
    "are used for direct comparison in Section 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e253fc2b-2e73-474f-8cf2-aa9fba8062cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy ReLU\n",
    "def relu_np(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# NumPy forward pass from Notebook 01\n",
    "def forward_single(x, W1, b1, W2, b2):\n",
    "    a1 = W1 @ x + b1            # (h,)\n",
    "    h  = relu_np(a1)            # (h,)\n",
    "    f  = W2 @ h + b2            # scalar\n",
    "    return a1, h, float(f.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f9bb4-49a9-406a-897d-bde7c9f292f3",
   "metadata": {},
   "source": [
    "## 4 .NumPy Model Parameters (for comparison)\n",
    "\n",
    "Notebook 02 needs standalone NumPy parameters to reproduce the exact\n",
    "forward pass used in Notebook 01. These are synchronized with the\n",
    "PyTorch parameters in Section 5 so both implementations produce\n",
    "identical outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e2fb68-9e2e-4a91-8186-f30284d2d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4.1 NumPy Parameters (copied from Notebook 01) ===\n",
    "\n",
    "d, h = 2, 4\n",
    "\n",
    "# Initialize NumPy parameters exactly like Notebook 01\n",
    "W1 = np.random.randn(h, d)\n",
    "b1 = np.random.randn(h)\n",
    "\n",
    "W2 = np.random.randn(1, h)\n",
    "b2 = np.random.randn(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312d2b3-776b-4436-8e37-5ec76979071f",
   "metadata": {},
   "source": [
    "## 5. Model Parameters in PyTorch (No Autograd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9febf33a-c316-4b3e-88cd-0deaacfaebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch parameters (initial values do NOT matter yet)\n",
    "W1_t = torch.randn(h, d, dtype=torch.float32)\n",
    "b1_t = torch.randn(h, dtype=torch.float32)\n",
    "W2_t = torch.randn(1, h, dtype=torch.float32)\n",
    "b2_t = torch.randn(1, dtype=torch.float32)\n",
    "\n",
    "# Disable autograd (for this notebook)\n",
    "for t in [W1_t, b1_t, W2_t, b2_t]:\n",
    "    t.requires_grad = False\n",
    "\n",
    "# --- Sync PyTorch parameters with NumPy parameters ---\n",
    "W1_t.data = torch.tensor(W1, dtype=torch.float32)\n",
    "b1_t.data = torch.tensor(b1, dtype=torch.float32)\n",
    "W2_t.data = torch.tensor(W2, dtype=torch.float32)\n",
    "b2_t.data = torch.tensor(b2, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e1b9d-f685-4c26-a749-3ad5cbdc7e7d",
   "metadata": {},
   "source": [
    "## 5. Activation Function\n",
    "#### Match NumPy ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6711a7ed-e190-4553-95cf-dd87b74abb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_t(x):\n",
    "    return torch.clamp(x, min=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed0b5e-44c8-454b-bb1a-ada378e8c3f9",
   "metadata": {},
   "source": [
    "## 6. Forward Pass (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac5e5a0-01eb-4cd7-9981-0fec9f791a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_torch(x, W1, b1, W2, b2):\n",
    "    a1 = x @ W1.T + b1          # (h,)\n",
    "    h  = relu_t(a1)             # (h,)\n",
    "    f  = W2 @ h + b2            # (1,)\n",
    "    return a1, h, f.squeeze()   # scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b4c5b-1e6a-4b9f-ba11-acf6375a4199",
   "metadata": {},
   "source": [
    "## 7. Loss Function\n",
    "#### Match NumPy MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aafde80-f281-4d57-aed2-8de231a950a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_t(f, y):\n",
    "    return (f - y)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d6636-ed17-41ed-908f-2065b81396ee",
   "metadata": {},
   "source": [
    "## 8. Numerical Consistency Test (NumPy vs Torch)\n",
    "We compare the NumPy output from Notebook 01 with the PyTorch output here.\n",
    "\n",
    "Pick a single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c97e4eca-5d37-4092-81e4-46a140c6fc52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "x_i_np = X_np[i]\n",
    "y_i_np = y_np[i]\n",
    "\n",
    "# Forward using NumPy functions (from Notebook 01)\n",
    "a1_np, h_np, f_np = forward_single(x_i_np, W1, b1, W2, b2)\n",
    "\n",
    "# Forward using PyTorch\n",
    "x_i_t = X[i]\n",
    "a1_t, h_t, f_t = forward_torch(x_i_t, W1_t, b1_t, W2_t, b2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a00217af-2538-4386-8dc4-0331bf61e4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy output f = -1.2906031334882266\n",
      "Torch output f = -1.2906031608581543\n",
      "Difference = 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"NumPy output f =\", f_np)\n",
    "print(\"Torch output f =\", float(f_t))\n",
    "print(\"Difference =\", float(abs(f_np - f_t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b9ceb-cbe0-4732-ba00-d20637185ca5",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "This notebook recreated the NumPy MLP from Notebook 01 using PyTorch tensors with requires_grad=False. After synchronizing parameters, both implementations produced numerically identical outputs, differing only by negligible float32 precision noise. This confirms that the PyTorch forward pass matches the analytical NumPy model exactly.\n",
    "\n",
    "With functional parity established, we are now ready to enable PyTorch autograd, compare automatic gradients to our manual backprop, and move toward a full training loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
