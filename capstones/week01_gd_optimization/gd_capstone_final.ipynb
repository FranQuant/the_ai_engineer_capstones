{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a274b1-1d62-4996-a137-5d5e76aa4aa8",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/FranQuant/the_ai_engineer_capstones/blob/main/capstones/week01_gd_optimization/gd_capstone_final.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72490247-b367-4f3b-bd4d-89c88d9575d1",
   "metadata": {},
   "source": [
    "# Gradient Descent Optimization Capstone\n",
    "\n",
    "This notebook implements the Week-1 Core Track capstone from *The AI Engineer*.\n",
    "\n",
    "We study gradient-based optimization on the one-dimensional objective\n",
    "\n",
    "$$\n",
    "f(x) = x^3 - 3x,\n",
    "$$\n",
    "\n",
    "with derivative\n",
    "\n",
    "$$\n",
    "f'(x) = 3x^2 - 3.\n",
    "$$\n",
    "\n",
    "This non-convex cubic has two real stationary points:\n",
    "\n",
    "- $x = -1$: local **maximum** (repelling under GD)\n",
    "- $x = +1$: local **minimum** (attracting under GD for $0 < \\eta < 1/3$)\n",
    "\n",
    "Although the function is non-convex, **Gradient Descent has only one true basin of attraction** for positive learning rates:\n",
    "\n",
    "- Initializations in $(-1, +1)$ or slightly to the right move toward $x = +1$.\n",
    "- Initializations left of $-1$ diverge toward $-\\infty$ unless a guard prevents it.\n",
    "- Only an initialization *exactly* at $x = -1$ remains there (measure-zero unstable fixed point).\n",
    "\n",
    "This makes the cubic ideal for illustrating:\n",
    "\n",
    "- Stability vs. instability of stationary points  \n",
    "- GD behavior in non-convex landscapes  \n",
    "- Sensitivity to initialization  \n",
    "- Effects of learning rate  \n",
    "- Differences between GD and noisy SGD  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11132a-ca0f-43b2-9f61-004dd65223b1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d6657-7b83-4b06-9e4b-a60a578f041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Setup\n",
    "# ============================================\n",
    "# 1. Setup\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib settings (clean, consistent)\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "# Global reproducibility\n",
    "MASTER_SEED = 42\n",
    "GLOBAL_RNG = np.random.default_rng(MASTER_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699c29f-56ef-4d35-9b8f-9a7e163b1a84",
   "metadata": {},
   "source": [
    "## 2. Define $f(x)$ and $f'(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36696a4b-31a3-47fc-b02e-dddd2aa910d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. Define f(x) and f'(x)\n",
    "# ============================================\n",
    "\n",
    "def f(x: float | np.ndarray) -> float | np.ndarray:\n",
    "    \"\"\"\n",
    "    Non-convex cubic objective:\n",
    "        f(x) = x^3 - 3x\n",
    "\n",
    "    Stationary points:\n",
    "        - x = -1  → f'(-1) = 0  (local maximum, unstable under GD)\n",
    "        - x = +1  → f'(+1) = 0  (local minimum, stable under GD for 0 < lr < 1/3)\n",
    "\n",
    "    Returns:\n",
    "        float or ndarray: objective evaluated at x\n",
    "    \"\"\"\n",
    "    return x**3 - 3.0 * x\n",
    "\n",
    "\n",
    "def df(x: float | np.ndarray) -> float | np.ndarray:\n",
    "    \"\"\"\n",
    "    Derivative of the objective:\n",
    "        f'(x) = 3x^2 - 3\n",
    "\n",
    "    This drives the GD update:\n",
    "        x_{k+1} = x_k - lr * f'(x_k)\n",
    "    \"\"\"\n",
    "    return 3.0 * x**2 - 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f989eb-be6c-413c-a54a-7e8d736cd2d5",
   "metadata": {},
   "source": [
    "## 3. Visualizing the Objective Function $f(x)$\n",
    "\n",
    "### Objective Function\n",
    "\n",
    "Before running any optimization, we visualize the non-convex cubic objective:\n",
    "\n",
    "$$\n",
    "f(x) = x^3 - 3x.\n",
    "$$\n",
    "\n",
    "Solving $f'(x)=0$ gives two stationary points:\n",
    "\n",
    "- A **local maximum** at $x = -1$ (unstable under gradient descent)\n",
    "- A **local minimum** at $x = +1$ (stable for $0 < \\text{lr} < 1/3$)\n",
    "\n",
    "Although the function has two stationary points, **gradient descent has only one\n",
    "true basin of attraction**:\n",
    "\n",
    "- Points initialized in $(-1, 1)$ move toward the stable minimum at $x = +1$\n",
    "- Points initialized exactly at $x = -1$ remain there (measure-zero case)\n",
    "- Points initialized $x_0 < -1$ move further negative and diverge unless a radius\n",
    "  guard is imposed\n",
    "\n",
    "The plot below helps contextualize the geometry driving the GD and SGD\n",
    "trajectories studied later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95697d-45ce-40be-8601-b969b99aacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. Visualize the objective f(x)\n",
    "# ============================================\n",
    "\n",
    "xs = np.linspace(-3, 3, 400)\n",
    "ys = f(xs)\n",
    "\n",
    "# Stationary points: solve f'(x) = 0 -> 3x^2 - 3 = 0 -> x = ±1\n",
    "x_crit = np.array([-1.0, 1.0])\n",
    "y_crit = f(x_crit)\n",
    "\n",
    "plt.plot(xs, ys, label=\"f(x)\", linewidth=2)\n",
    "\n",
    "# Highlight stationary points\n",
    "plt.scatter(x_crit, y_crit, color=\"red\", zorder=5)\n",
    "for xc, yc in zip(x_crit, y_crit):\n",
    "    plt.annotate(\n",
    "        rf\"$x={xc:.0f}$\",\n",
    "        xy=(xc, yc),\n",
    "        xytext=(xc + 0.2, yc + 4),\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"red\"),\n",
    "        fontsize=11\n",
    "    )\n",
    "\n",
    "plt.title(\"Objective Function $f(x)$\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640b6d7a-71e2-4829-9109-75942b786a73",
   "metadata": {},
   "source": [
    "## 4. Gradient Descent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d37844-cbc8-413e-8b49-6162eb1d2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. Gradient Descent (GD)\n",
    "# ============================================\n",
    "\n",
    "def gd(x0: float, lr: float = 0.05, steps: int = 50,\n",
    "       grad_tol: float = 1e-6, max_radius: float = 10.0):\n",
    "    \"\"\"\n",
    "    Perform standard Gradient Descent (GD) on f(x), with guards.\n",
    "\n",
    "    Args:\n",
    "        x0 (float): initial point\n",
    "        lr (float): learning rate\n",
    "        steps (int): max number of iterations\n",
    "        grad_tol (float): stop if |f'(x)| < grad_tol\n",
    "        max_radius (float): divergence guard (stop if |x| > max_radius)\n",
    "\n",
    "    Returns:\n",
    "        traj (np.ndarray): trajectory of x-values across iterations\n",
    "        status (str): \"ok\", \"converged\", or descriptive divergence label\n",
    "    \"\"\"\n",
    "    x = float(x0)\n",
    "    traj = [x]\n",
    "\n",
    "    for k in range(steps):\n",
    "        grad = df(x)\n",
    "\n",
    "        # Convergence condition\n",
    "        if abs(grad) < grad_tol:\n",
    "            return np.array(traj), \"converged\"\n",
    "\n",
    "        # Gradient update\n",
    "        x_next = x - lr * grad\n",
    "\n",
    "        # Divergence guard\n",
    "        if abs(x_next) > max_radius:\n",
    "            traj.append(x_next)\n",
    "            return np.array(traj), f\"diverged (|x|>{max_radius} at iter {k+1})\"\n",
    "\n",
    "        traj.append(x_next)\n",
    "        x = x_next\n",
    "\n",
    "    return np.array(traj), \"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ae595-2071-4ee0-ba76-7b2ee20b8c1b",
   "metadata": {},
   "source": [
    "## 5. Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74118b-0d7a-4582-85d6-9f77ff66e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5. Stochastic Gradient Descent (SGD)\n",
    "# ============================================\n",
    "\n",
    "def sgd(x0: float, lr: float = 0.05, steps: int = 50,\n",
    "        noise_scale: float = 0.1, seed: int = MASTER_SEED,\n",
    "        max_radius: float = 10.0):\n",
    "    \"\"\"\n",
    "    Perform Stochastic Gradient Descent (SGD) on f(x) by injecting\n",
    "    Gaussian noise into the gradient, simulating minibatch variability.\n",
    "\n",
    "    Args:\n",
    "        x0 (float): initial point\n",
    "        lr (float): learning rate\n",
    "        steps (int): max number of iterations\n",
    "        noise_scale (float): std dev of injected gradient noise\n",
    "        seed (int): RNG seed for reproducibility\n",
    "        max_radius (float): divergence guard\n",
    "\n",
    "    Returns:\n",
    "        traj (np.ndarray): trajectory of x-values across iterations\n",
    "        status (str): \"ok\" or descriptive divergence status\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = float(x0)\n",
    "    traj = [x]\n",
    "\n",
    "    for k in range(steps):\n",
    "        grad = df(x)\n",
    "        noise = rng.normal(scale=noise_scale)\n",
    "\n",
    "        # noisy gradient\n",
    "        grad_noisy = grad + noise\n",
    "\n",
    "        x_next = x - lr * grad_noisy\n",
    "\n",
    "        # Divergence guard\n",
    "        if abs(x_next) > max_radius:\n",
    "            traj.append(x_next)\n",
    "            return np.array(traj), f\"diverged (|x|>{max_radius} at iter {k+1})\"\n",
    "\n",
    "        traj.append(x_next)\n",
    "        x = x_next\n",
    "\n",
    "    return np.array(traj), \"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43ccfa-861d-486b-b22e-bf407378ef40",
   "metadata": {},
   "source": [
    "## 6. GD vs SGD: Loss and Parameter Trajectories\n",
    "\n",
    "To fully understand the difference between gradient descent (GD) and stochastic\n",
    "gradient descent (SGD), we visualize both:\n",
    "\n",
    "1. **Loss trajectories**  \n",
    "   $f(x_k)$ decreases smoothly for GD.  \n",
    "   For SGD, the injected noise makes the loss *non-monotonic* and jagged,\n",
    "   especially when the noise scale is large. Near the minimizer, the surface\n",
    "   is flat, so the noise may partially mask curvature.\n",
    "\n",
    "2. **Parameter trajectories**  \n",
    "   GD follows a smooth deterministic path.  \n",
    "   SGD shows characteristic zig-zag motion and fluctuates around the minimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256009e-cb7b-41f4-8d3f-e516a8261b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6. GD vs SGD: loss and parameter trajectories\n",
    "# ============================================\n",
    "\n",
    "# Run GD and SGD with consistent seeds and tuned parameters\n",
    "traj_gd, status_gd = gd(x0=4.0, lr=0.05, steps=60)\n",
    "traj_sgd, status_sgd = sgd(\n",
    "    x0=4.0, lr=0.05, steps=60,\n",
    "    noise_scale=4.0, seed=MASTER_SEED\n",
    ")\n",
    "\n",
    "# Compute loss values\n",
    "loss_gd = f(traj_gd)\n",
    "loss_sgd = f(traj_sgd)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(7, 8))\n",
    "\n",
    "# --------------------------------------------\n",
    "# (1) Loss trajectories\n",
    "# --------------------------------------------\n",
    "axes[0].plot(loss_gd, label=f\"GD — {status_gd}\", linewidth=2)\n",
    "axes[0].plot(loss_sgd, label=f\"SGD — {status_sgd}\", linewidth=2)\n",
    "\n",
    "axes[0].set_title(\"Loss Trajectories: GD vs SGD\")\n",
    "axes[0].set_xlabel(\"Iteration\")\n",
    "axes[0].set_ylabel(\"f(x)\")\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "# --------------------------------------------\n",
    "# (2) Parameter trajectories\n",
    "# --------------------------------------------\n",
    "axes[1].plot(traj_gd, label=f\"GD — {status_gd}\", linewidth=2)\n",
    "axes[1].plot(traj_sgd, label=f\"SGD — {status_sgd}\", linewidth=2)\n",
    "\n",
    "axes[1].axhline(1.0, color=\"black\", linestyle=\"--\", linewidth=1, label=\"x* = +1\")\n",
    "axes[1].set_title(\"Parameter Trajectories: GD vs SGD\")\n",
    "axes[1].set_xlabel(\"Iteration\")\n",
    "axes[1].set_ylabel(\"x\")\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e730b-b212-46af-98a5-6e901675cfab",
   "metadata": {},
   "source": [
    "## 7. Convergence Diagnostics — Objective Gap\n",
    "\n",
    "To measure how quickly GD and SGD approach the *local minimizer* at $x^* = 1$,  \n",
    "we evaluate the **objective gap**:\n",
    "\n",
    "$$\n",
    "f(x_k) - f(x^*).\n",
    "$$\n",
    "\n",
    "The cubic $f(x) = x^3 - 3x$ has two stationary points ($x=-1$ and $x=1$),  \n",
    "but **only $x=1$ is stable under gradient descent for any positive step size**.  \n",
    "The point $x=-1$ is a *repelling* stationary point, so GD will not converge to it\n",
    "unless the initialization is exactly $x=-1$ (a measure-zero event).\n",
    "\n",
    "Therefore, all *stable* convergence behavior should be evaluated relative to $x^*=1$.\n",
    "\n",
    "To avoid falsely reporting divergence as convergence, we do **not** clip negative\n",
    "gaps; instead we mark any iteration where $f(x_k) < f(x^*)$ as *divergent* in the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6fe63-52d4-4097-907b-1916d110faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7. Convergence Diagnostics: Objective Gap\n",
    "# ============================================\n",
    "\n",
    "# True minimizer (local minimum of x^3 - 3x)\n",
    "x_star = 1.0\n",
    "f_star = f(x_star)\n",
    "\n",
    "def objective_gap(traj, f_star):\n",
    "    \"\"\"\n",
    "    f(x_k) - f(x*) for each iteration.\n",
    "    If f(x_k) < f_star (i.e., the run moved into the unbounded-below region),\n",
    "    we mark the gap as NaN so the log plot reveals divergence.\n",
    "    \"\"\"\n",
    "    gap = f(traj) - f_star\n",
    "    gap = np.where(gap >= 0, gap, np.nan)\n",
    "    return gap\n",
    "\n",
    "# Compute gaps\n",
    "gap_gd = objective_gap(traj_gd, f_star)\n",
    "gap_sgd = objective_gap(traj_sgd, f_star)\n",
    "\n",
    "# Plot on log scale\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.semilogy(gap_gd, label=f\"GD — {status_gd}\", linewidth=2)\n",
    "plt.semilogy(gap_sgd, label=f\"SGD — {status_sgd}\", linewidth=2)\n",
    "\n",
    "plt.title(\"Objective Gap: $f(x_k) - f(x^*)$\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Gap (log scale)\")\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c3d09-095d-4fc6-80c9-a744a9f72ca0",
   "metadata": {},
   "source": [
    "## 8. Step-Size Sensitivity (Learning-Rate Sweep)\n",
    "\n",
    "To study how the learning rate affects gradient descent dynamics on the cubic\n",
    "objective\n",
    "\n",
    "$$\n",
    "f(x) = x^3 - 3x,\n",
    "$$\n",
    "\n",
    "we run GD from an initial point $x_0 = 4.5$ using several learning rates:\n",
    "\n",
    "- **Too small** → slow but stable  \n",
    "- **Moderate** → fast and stable  \n",
    "- **Too large** → overshoot and divergence  \n",
    "\n",
    "Because this cubic is **unbounded below**, overly large steps can push $x_k$ out\n",
    "of the right-hand basin and into a runaway trajectory. To prevent numerical\n",
    "instabilities, we halt any run that leaves the safety region $|x| \\le 5$ and\n",
    "label it **diverged**.\n",
    "\n",
    "This experiment demonstrates the classical learning-rate trade-off in\n",
    "non-convex optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03020de6-87b5-4378-a642-2c56bfca75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8. Learning-Rate Sensitivity (GD)\n",
    "# ============================================\n",
    "\n",
    "def gd_guarded(x0, lr, steps, radius=5.0, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Gradient Descent with a safety radius and convergence check.\n",
    "\n",
    "    Args:\n",
    "        x0 (float): initial point\n",
    "        lr (float): learning rate\n",
    "        steps (int): number of iterations\n",
    "        radius (float): stop if |x| > radius (divergence guard)\n",
    "        tol (float): stop early if |grad| < tol\n",
    "\n",
    "    Returns:\n",
    "        traj (np.ndarray): sequence of x-values\n",
    "        status (str): \"converged\", \"diverged\", or \"finished\"\n",
    "    \"\"\"\n",
    "    x = float(x0)\n",
    "    traj = [x]\n",
    "\n",
    "    for k in range(steps):\n",
    "        grad = df(x)\n",
    "        x_new = x - lr * grad\n",
    "\n",
    "        # Divergence guard\n",
    "        if abs(x_new) > radius:\n",
    "            traj.append(x_new)\n",
    "            return np.array(traj), \"diverged\"\n",
    "\n",
    "        # Convergence check\n",
    "        if abs(grad) < tol:\n",
    "            traj.append(x_new)\n",
    "            return np.array(traj), \"converged\"\n",
    "\n",
    "        x = x_new\n",
    "        traj.append(x)\n",
    "\n",
    "    return np.array(traj), \"finished\"\n",
    "\n",
    "\n",
    "# Learning-rate sweep\n",
    "lrs   = [0.001, 0.01, 0.05, 0.10]   # small → moderate → fast → too large\n",
    "steps = 50\n",
    "x0    = 4.5\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for lr in lrs:\n",
    "    traj, status = gd_guarded(x0=x0, lr=lr, steps=steps)\n",
    "    iters = np.arange(len(traj))\n",
    "    plt.plot(iters, f(traj), label=f\"lr={lr} ({status})\", linewidth=2)\n",
    "\n",
    "plt.title(\"GD Learning-Rate Sensitivity\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2a83c-375c-4a30-8980-5ac1256615c4",
   "metadata": {},
   "source": [
    "## 9. Local Geometry Plot\n",
    "\n",
    "This figure illustrates the core mechanism behind **gradient descent**.\n",
    "\n",
    "At the current iterate $x_0$, we approximate the objective using its **tangent line**.  \n",
    "The derivative $f'(x_0)$ gives the local slope, and the gradient–descent update\n",
    "\n",
    "$$\n",
    "x_1 = x_0 - \\eta\\, f'(x_0)\n",
    "$$\n",
    "\n",
    "moves the iterate in the direction of steepest descent.\n",
    "\n",
    "In the plot:\n",
    "\n",
    "- **Blue curve**: true objective $f(x)$  \n",
    "- **Red line**: tangent line at $x_0$  \n",
    "- **Black point**: current iterate $x_0$  \n",
    "- **Green point**: next iterate $x_1$ after applying the GD update  \n",
    "\n",
    "This visualization highlights how GD uses the **local linear approximation** of the function to determine the next step downhill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed5c99-3ba2-4643-baee-392dd648206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9. Local Geometry of a Gradient Step\n",
    "# ============================================\n",
    "\n",
    "x0  = 2.0       # point where we linearize\n",
    "eta = 0.2       # step size\n",
    "x1  = x0 - eta * df(x0)\n",
    "\n",
    "# Tangent line at x0\n",
    "xs = np.linspace(1.2, 2.8, 200)\n",
    "tangent = f(x0) + df(x0) * (xs - x0)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(xs, f(xs), label=\"f(x)\", linewidth=2)\n",
    "plt.plot(xs, tangent, label=\"Tangent line\", color=\"red\", linewidth=2)\n",
    "\n",
    "plt.scatter([x0], [f(x0)], color=\"black\", label=\"x0\", zorder=5)\n",
    "plt.scatter([x1], [f(x1)], color=\"green\", label=r\"$x1 = x0 - \\eta f'(x0)$\", zorder=5)\n",
    "\n",
    "plt.title(\"Local Geometry of a Gradient Step\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98428a2-ab37-4ba4-90d1-8bdc523184d8",
   "metadata": {},
   "source": [
    "## 10. Gradient Descent from Multiple Initializations\n",
    "\n",
    "We examine how initialization affects gradient descent on the cubic\n",
    "\n",
    "$$\n",
    "f(x) = x^3 - 3x,\n",
    "$$\n",
    "\n",
    "which has two stationary points:\n",
    "\n",
    "- A local **maximum** at $x = -1$\n",
    "- A local **minimum** at $x = 1$\n",
    "\n",
    "A key subtlety is the **stability** of these stationary points:\n",
    "\n",
    "- $x = 1$ is **stable** under gradient descent for step sizes $0 < \\eta < \\tfrac{1}{3}$.\n",
    "- $x = -1$ is **always unstable** for any $\\eta > 0$ (because the update multiplier $1 + 6\\eta$ has magnitude $> 1$).\n",
    "\n",
    "This means:\n",
    "\n",
    "- Only exact initialization at $x = -1$ stays at the maximum (a measure–zero condition).\n",
    "- Any slight perturbation near $x = -1$ moves **away** from the maximum.\n",
    "- All initializations in the interval $(-1, 1)$ move **toward** the local minimum at $x = 1$.\n",
    "- Initializations far to the right may overshoot depending on the learning rate.\n",
    "\n",
    "We demonstrate this by launching gradient descent from\n",
    "\n",
    "$$\n",
    "x_0 \\in \\{-1.0,\\; 0.5,\\; 2.0\\}\n",
    "$$\n",
    "\n",
    "and plotting their trajectories as functions of iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e7c4e-06d1-4fab-83dd-f10c9d9de5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10. GD Trajectories from Multiple Initializations\n",
    "# ============================================\n",
    "\n",
    "def gd_guarded(x0, lr, steps=50, radius=6.0):\n",
    "    \"\"\"Gradient descent with guard against runaway divergence.\"\"\"\n",
    "    x = x0\n",
    "    traj = [x]\n",
    "    for k in range(steps):\n",
    "        grad = df(x)\n",
    "        x_new = x - lr * grad\n",
    "\n",
    "        if abs(x_new) > radius:\n",
    "            return np.array(traj), \"diverged\"\n",
    "\n",
    "        x = x_new\n",
    "        traj.append(x)\n",
    "\n",
    "    return np.array(traj), \"ok\"\n",
    "\n",
    "\n",
    "eta = 0.05\n",
    "inits = [-1.0, 0.5, 2.0]\n",
    "steps = 50\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for x0 in inits:\n",
    "    traj, status = gd_guarded(x0, eta, steps)\n",
    "    plt.plot(traj, label=f\"x0={x0} ({status})\", linewidth=2)\n",
    "\n",
    "plt.title(\"GD Trajectories from Multiple Initializations\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb092a-23c1-4681-80b1-bb5917b37aa6",
   "metadata": {},
   "source": [
    "# 11. Final Commentary and Key Takeaways\n",
    "\n",
    "This notebook reconstructed the core gradient-based optimization concepts from Week 1 — GD Optimization, using the non-convex cubic objective:\n",
    "\n",
    "$$\n",
    "f(x) = x^3 - 3x\n",
    "$$\n",
    "\n",
    "which has a local maximum at $x = -1$ and a local minimum at $x = 1$. This setup allows us to study gradient methods in a landscape with multiple stationary points but only one stable attractor.\n",
    "\n",
    "## 1. Gradient Descent (GD) Dynamics\n",
    "\n",
    "- GD follows a smooth, deterministic trajectory shaped purely by $f'(x)$ and the step size $\\eta$.\n",
    "- The stationary point at $x = 1$ is stable for $0 < \\eta < \\tfrac{1}{3}$.\n",
    "- The stationary point at $x = -1$ is unstable for any $\\eta > 0$ because the update multiplier $1 + 6\\eta$ has magnitude greater than 1.\n",
    "- Thus GD converges to $x = 1$ unless initialized exactly at $x = -1$.\n",
    "\n",
    "## 2. Stochastic Gradient Descent (SGD)\n",
    "\n",
    "- SGD injects Gaussian noise into the gradient, producing zig-zag parameter paths.\n",
    "- The noise barely shows up in the loss curve, but it strongly affects the movement in parameter space.\n",
    "- Near the minimizer, SGD settles into a steady-state variance driven by $\\eta$ and the noise scale.\n",
    "\n",
    "## 3. Step-Size Sensitivity\n",
    "\n",
    "- **Small $\\eta$**: slow but stable.\n",
    "- **Moderate $\\eta$**: fastest convergence.\n",
    "- **Large $\\eta$**: overshooting and eventual divergence.\n",
    "- A safety radius prevents numerical blow-ups and helps classify divergence.\n",
    "\n",
    "## 4. Local Geometry Interpretation\n",
    "\n",
    "- The tangent-line visualization shows that GD performs updates based on the local linearization of $f(x)$.\n",
    "- Large gradients lead to large steps; near stationary points the gradients shrink and convergence slows.\n",
    "- This provides geometric intuition for the contraction behavior near the minimizer.\n",
    "\n",
    "## 5. Effect of Initialization\n",
    "\n",
    "- Only exact initialization at $x = -1$ remains at the maximum (measure-zero event).\n",
    "- Any initialization in $(-1, 1)$ flows toward the stable minimizer at $x = 1$.\n",
    "- Initializations right of $1$ may converge or may overshoot depending on $\\eta$.\n",
    "\n",
    "## Overall Summary\n",
    "\n",
    "This notebook presented a clear, mathematically correct, fully reproducible exploration of:\n",
    "\n",
    "- deterministic vs. stochastic gradient behavior,\n",
    "- convergence rates and geometry,\n",
    "- learning-rate trade-offs,\n",
    "- stability of stationary points,\n",
    "- and the role of initialization in non-convex optimization.\n",
    "\n",
    "These insights form the foundation of the Gradient Descent Optimization module in The AI Engineer capstone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
