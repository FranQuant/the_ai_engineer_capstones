{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f409989c",
   "metadata": {},
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=35% align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02dd29a",
   "metadata": {
    "id": "t"
   },
   "source": [
    "# AI Agents & Automation \u2014 Chapter 5\n",
    "## Memory and State\n",
    "\n",
    "&copy; Dr. Yves J. Hilpisch<br>\n",
    "AI-Powered by GPT-5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce1b9d",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This notebook accompanies Chapter 5 \u2014 Memory State. It is self-contained and demonstrates the core ideas with small, readable code cells. Run cells from top to bottom; each code cell is preceded by a short explanation of what it does.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc7b80",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "We implement a tiny memory store with cosine similarity (NumPy) and a short summary function for the last N entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2496d2",
   "metadata": {
    "id": "pip"
   },
   "outputs": [],
   "source": [
    "%pip install -q numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150166a8",
   "metadata": {},
   "source": [
    "#### What This Cell Does\n",
    "\n",
    "This cell imports modules and sets up small helpers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dc029",
   "metadata": {
    "id": "code"
   },
   "outputs": [],
   "source": [
    "import re  # import regular expressions\n",
    "import numpy as np  # import NumPy for vectors\n",
    "\n",
    "class Store:\n",
    "    \"\"\"Tiny bag-of-words memory with cosine similarity.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.entries = []  # store raw texts\n",
    "        self.vocab = {}  # map token -> index\n",
    "\n",
    "    def _tokens(self, text: str) -> list[str]:\n",
    "        return re.findall(r'[A-Za-z0-9_]+', text.lower())  # tokenize text\n",
    "\n",
    "    def _vector(self, text: str) -> np.ndarray:\n",
    "        tokens = self._tokens(text)  # collect tokens\n",
    "        for token in tokens:\n",
    "            self.vocab.setdefault(token, len(self.vocab))  # add new token\n",
    "        vec = np.zeros(len(self.vocab), dtype=float)  # allocate vector\n",
    "        for token in tokens:\n",
    "            vec[self.vocab[token]] += 1.0  # count occurrences\n",
    "        norm = np.linalg.norm(vec) or 1.0  # avoid divide by zero\n",
    "        return vec / norm  # normalize vector\n",
    "\n",
    "    def _pad(\n",
    "        self,\n",
    "        entry_vec: np.ndarray,\n",
    "        query_vec: np.ndarray,\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        size = max(len(entry_vec), len(query_vec))  # target length\n",
    "        padded_entry = np.zeros(size, dtype=float)  # allocate entry buffer\n",
    "        padded_query = np.zeros(size, dtype=float)  # allocate query buffer\n",
    "        padded_entry[: len(entry_vec)] = entry_vec  # copy entry values\n",
    "        padded_query[: len(query_vec)] = query_vec  # copy query values\n",
    "        return padded_entry, padded_query  # equal-length vectors\n",
    "\n",
    "    def add(self, text: str) -> None:\n",
    "        self.entries.append(text)  # append new entry\n",
    "\n",
    "    def top(self, query: str, k: int = 1):\n",
    "        query_vec = self._vector(query)  # vectorize query\n",
    "        scores = []  # collect scores\n",
    "        for entry in self.entries:\n",
    "            entry_vec = self._vector(entry)  # vectorize entry\n",
    "            entry_vec, padded_query = self._pad(entry_vec, query_vec)  # pad lengths\n",
    "            score = float(entry_vec @ padded_query)  # cosine similarity\n",
    "            scores.append((entry, score))  # store score\n",
    "        return sorted(scores, key=lambda pair: pair[1], reverse=True)[:k]  # top-k\n",
    "\n",
    "    def summarize(self, n: int = 2) -> str:\n",
    "        window = '\\n'.join(self.entries[-n:])  # combine last notes\n",
    "        highlights = [\n",
    "            word\n",
    "            for word in window.split()\n",
    "            if word.isdigit() or (word[:1].isupper() and word[1:].islower())\n",
    "        ]  # pick salient tokens\n",
    "        return '\\n'.join(highlights) or 'n/a'  # return highlight list\n",
    "\n",
    "\n",
    "def demo() -> None:\n",
    "    store = Store()  # create memory\n",
    "    store.add('Calculate 2 and 3')  # add numeric note\n",
    "    store.add('Email Alice the PDF')  # add named note\n",
    "    print(store.top('add numbers', 1))  # show best match\n",
    "    print(store.summarize(2))  # show highlights\n",
    "\n",
    "\n",
    "demo()  # run demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223dffb9",
   "metadata": {},
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=35% align=right>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}